{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45599e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pyhdf.SD import SD, SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ab0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b3b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "directory_path = '/home/data/ywang/modis-dsr-2022/'\n",
    "\n",
    "# Define the pattern to match files\n",
    "pattern = \"MCD18C1.A*.061.*\"\n",
    "\n",
    "# Create the full path with pattern\n",
    "full_path_pattern = os.path.join(directory_path, pattern)\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "matching_files = glob.glob(full_path_pattern)\n",
    "matching_files.sort()\n",
    "dsrl = matching_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3d8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "directory_path = '/home/data/ywang/modis-par-2022/'\n",
    "\n",
    "# Define the pattern to match files\n",
    "pattern = \"MCD18C1.A*.061.*\"\n",
    "\n",
    "# Create the full path with pattern\n",
    "full_path_pattern = os.path.join(directory_path, pattern)\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "matching_files = glob.glob(full_path_pattern)\n",
    "matching_files.sort()\n",
    "parl = matching_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e39843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zoom_factors(lat_A, lon_A, lat_B, lon_B):\n",
    "    \"\"\"Calculate zoom factors for latitude and longitude dimensions.\"\"\"\n",
    "    zoom_factor_lat = len(lat_A) / len(lat_B)\n",
    "    zoom_factor_lon = len(lon_A) / len(lon_B)\n",
    "    return (zoom_factor_lat, zoom_factor_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed59ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def resample_dataset_B(data_B, zoom_factors):\n",
    "    \"\"\"Resample Dataset B spatially to match Dataset A's resolution.\"\"\"\n",
    "    resampled_B = np.empty((data_B.shape[0], int(data_B.shape[1] * zoom_factors[0]), int(data_B.shape[2] * zoom_factors[1])))\n",
    "    for i in range(data_B.shape[0]):\n",
    "        resampled_B[i] = zoom(data_B[i], zoom_factors, order=1)  # Using bilinear interpolation (order=1)\n",
    "    return resampled_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29ff640",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_A = np.arange(90, -90.25, -0.25)\n",
    "lon_A = np.arange(0, 360, 0.25)\n",
    "lat_B = np.arange(90, -90, -0.05)\n",
    "lon_B = np.arange(-180, 180, 0.05)\n",
    "\n",
    "# Convert longitudes from -180 to 180 range to 0 to 360 range\n",
    "lon_B_t = np.mod(lon_B + 360, 360)\n",
    "\n",
    "# Get the indices that would sort the longitude array\n",
    "sorted_indices = np.argsort(lon_B_t)\n",
    "\n",
    "# Use these indices to sort both the longitude array and the target array\n",
    "lon_B_adj = lon_B_t[sorted_indices]\n",
    "\n",
    "# Assuming lat_A and lon_A are defined with your desired target resolution and extent\n",
    "zoom_factors = calculate_zoom_factors(lat_A, lon_A, lat_B, lon_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c450e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf_variables(file_name):\n",
    "    hdf = SD(file_name, SDC.READ)\n",
    "    vars_data = []\n",
    "    for ds_name in hdf.datasets().keys():\n",
    "        dataset = hdf.select(ds_name)\n",
    "        data = dataset.get()\n",
    "        data = np.where(data == -1, np.nan, data)\n",
    "        vars_data.append(data)\n",
    "    hdf.end()\n",
    "    vars_data = np.array(vars_data)\n",
    "    return vars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd742de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_rad(data):\n",
    "    dataa = data[:, :, sorted_indices]\n",
    "    datar = resample_dataset_B(dataa, zoom_factors)\n",
    "    return datar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525bc8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022001.061.2022058062929.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022002.061.2022058063131.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022003.061.2022058063737.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022004.061.2022058063838.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022005.061.2022058063939.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022006.061.2022059143939.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022007.061.2022059152121.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022008.061.2022059152828.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022009.061.2022059154646.hdf\n",
      "/home/data/ywang/modis-dsr-2022/MCD18C1.A2022010.061.2022059163737.hdf\n"
     ]
    }
   ],
   "source": [
    "dsr = []\n",
    "\n",
    "for file_path in dsrl:\n",
    "    array = read_hdf_variables(file_path)\n",
    "    dsrr = remap_rad(array)\n",
    "    dsr.append(dsrr)\n",
    "\n",
    "dsr = np.concatenate(dsr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ab844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = []\n",
    "\n",
    "for file_path in dsrl:\n",
    "    array = read_hdf_variables(file_path)\n",
    "    parr = remap_rad(array)\n",
    "    par.append(parr)\n",
    "\n",
    "par = np.concatenate(par, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8b12516",
   "metadata": {},
   "outputs": [],
   "source": [
    "era = xr.open_dataset('/home/data/ywang/adaptor.mars.internal-1713218677.3867846-29785-15-4cc9d748-57e1-4a66-ac75-1a459ea0d3f4.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "358c799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_variables(variable_name):\n",
    "    variable = era[variable_name]\n",
    "    scale_factor = variable.attrs.get('scale_factor', 1)\n",
    "    add_offset = variable.attrs.get('add_offset', 0)\n",
    "    missing_value = variable.attrs.get('missing_value', None)\n",
    "    _fill_value = variable.attrs.get('_FillValue', None)\n",
    "    adjusted_variable = variable * scale_factor + add_offset\n",
    "    if missing_value is not None:\n",
    "        adjusted_variable = adjusted_variable.where(adjusted_variable != missing_value, other=np.nan)\n",
    "    if _fill_value is not None:\n",
    "        adjusted_variable = adjusted_variable.where(adjusted_variable != _fill_value, other=np.nan)\n",
    "    return adjusted_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd3a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "fal = read_nc_variables('fal').values\n",
    "tcc = read_nc_variables('tcc').values\n",
    "tcw = read_nc_variables('tcw').values\n",
    "tco3 = read_nc_variables('tco3').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "634c643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([dsr, fal, tcc, tcw, tco3], axis=-1)\n",
    "y = par[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f054bc1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'sace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7d6c4945809d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'sace'"
     ]
    }
   ],
   "source": [
    "np.save('X.npy', X)\n",
    "np.sace('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a26466e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fee0f74",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1994664082c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mscaler_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mscaler_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0my_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_seen_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m                     _incremental_mean_and_var(X, self.mean_, self.var_,\n\u001b[0m\u001b[1;32m    850\u001b[0m                                               self.n_samples_seen_)\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_incremental_mean_and_var\u001b[0;34m(X, last_mean, last_variance, last_sample_count)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         new_unnormalized_variance = (\n\u001b[0;32m--> 853\u001b[0;31m             _safe_accumulator_op(np.nanvar, X, axis=0) * new_sample_count)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0mlast_unnormalized_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_variance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlast_sample_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mnanvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m     \"\"\"\n\u001b[0;32m-> 1706\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m         return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36m_replace_nan\u001b[0;34m(a, val)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stack arrays together to make handling easier\n",
    "X = np.stack([dsr, fal, tcc, tcw, tco3], axis=-1)\n",
    "y = par[..., np.newaxis]\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reshape data for scaling\n",
    "n_train, lat, lon, channels = X_train.shape\n",
    "X_train_flat = X_train.reshape(-1, channels)\n",
    "X_val_flat = X_val.reshape(-1, channels)\n",
    "X_test_flat = X_test.reshape(-1, channels)\n",
    "y_train_flat = y_train.reshape(-1, 1)\n",
    "y_val_flat = y_val.reshape(-1, 1)\n",
    "y_test_flat = y_test.reshape(-1, 1)\n",
    "\n",
    "# Initialize and fit the StandardScaler on the training data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_flat)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train_flat)\n",
    "\n",
    "# Transform validation and test data with the same scaler\n",
    "X_val_scaled = scaler_X.transform(X_val_flat)\n",
    "X_test_scaled = scaler_X.transform(X_test_flat)\n",
    "y_val_scaled = scaler_y.transform(y_val_flat)\n",
    "y_test_scaled = scaler_y.transform(y_test_flat)\n",
    "\n",
    "# Reshape back to the original dimensions\n",
    "X_train = X_train_scaled.reshape(n_train, lat, lon, channels)\n",
    "X_val = X_val_scaled.reshape(len(X_val), lat, lon, channels)\n",
    "X_test = X_test_scaled.reshape(len(X_test), lat, lon, channels)\n",
    "y_train = y_train_scaled.reshape(n_train, lat, lon, 1)\n",
    "y_val = y_val_scaled.reshape(len(y_val), lat, lon, 1)\n",
    "y_test = y_test_scaled.reshape(len(y_test), lat, lon, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61189765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
